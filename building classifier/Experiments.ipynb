{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from preprocessing import remove_punct_num\n",
    "from preprocessing import remove_stopwords\n",
    "from preprocessing import stemmer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/experiment1/shuffled.csv')\n",
    "X, y = df['content'], df['multiclass']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)\n",
    "# random_state = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1696, 22824)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1) #  max_features=100, binary=True, norm=None, use_idf=False\n",
    "X= vectorizer.fit_transform(X_train) \n",
    "train_data_features = X.toarray()\n",
    "\n",
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1696, 31074)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, binary=True, norm=None, use_idf=False) #max_features=5000 #\n",
    "X= vectorizer.fit_transform(X_train) \n",
    "train_data_features = X.toarray()\n",
    "\n",
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC(C=1.0,random_state=42, max_iter=1000)) # C=1.0\n",
    "clf.fit(train_data_features,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(train_data_features,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n"
     ]
    }
   ],
   "source": [
    "test_data_features = vectorizer.transform(X_test)\n",
    "pred = clf.predict(test_data_features)\n",
    "accuracy = clf.score(test_data_features,y_test)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print pred\n",
    "# print pred.shape\n",
    "# print y_test.values\n",
    "\n",
    "X_testArray = X_test.values\n",
    "y_testArray = y_test.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0=crime 1=disaster 2=entertainment 3=economic 4=health 5=political 6=sports 7=terrorism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59  1  0  2  0  1  0  1]\n",
      " [ 2 63  0  0  0  1  0  0]\n",
      " [ 0  0 72  0  0  0  0  0]\n",
      " [ 0  2  0 37  0  9  0  0]\n",
      " [ 0  2  0  0 20  1  0  1]\n",
      " [ 2  1  0  2  0 64  0  2]\n",
      " [ 0  0  1  0  0  0 63  0]\n",
      " [ 0  0  0  0  0  3  0 13]]\n"
     ]
    }
   ],
   "source": [
    "# row : actual :: column : predicted \n",
    "cf = confusion_matrix(y_testArray,pred)\n",
    "print cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime\n",
      "59 5 4 357\n",
      "Precision:  0.936507936508\n",
      "Recall:  0.921875\n",
      " \n",
      "Disaster\n",
      "63 3 6 353\n",
      "Precision:  0.913043478261\n",
      "Recall:  0.954545454545\n",
      " \n",
      "Entertainment\n",
      "72 0 1 352\n",
      "Precision:  0.986301369863\n",
      "Recall:  1.0\n",
      " \n",
      "Economic\n",
      "37 11 4 373\n",
      "Precision:  0.90243902439\n",
      "Recall:  0.770833333333\n",
      " \n",
      "Health\n",
      "20 4 0 401\n",
      "Precision:  1.0\n",
      "Recall:  0.833333333333\n",
      " \n",
      "Political\n",
      "64 7 15 339\n",
      "Precision:  0.810126582278\n",
      "Recall:  0.901408450704\n",
      " \n",
      "Sports\n",
      "63 1 0 361\n",
      "Precision:  1.0\n",
      "Recall:  0.984375\n",
      " \n",
      "Terrorism\n",
      "13 3 4 405\n",
      "Precision:  0.764705882353\n",
      "Recall:  0.8125\n",
      " \n",
      "hey  391 34 34 2941\n"
     ]
    }
   ],
   "source": [
    "# 8 total classes\n",
    "from __future__ import division\n",
    "\n",
    "total = 8\n",
    "classes = {0:'Crime', 1:'Disaster', 2:'Entertainment', 3:'Economic', 4:'Health', 5:'Political',\n",
    "          6:'Sports', 7:'Terrorism'}\n",
    "category = 0\n",
    "\n",
    "TrueP = []\n",
    "FalseN = []\n",
    "FalseP = []\n",
    "TrueN = []\n",
    "\n",
    "\n",
    "for category in range(total):\n",
    "    TP = FN = FP = TN = 0 \n",
    "    for i in range(total):\n",
    "        for j in range(total):\n",
    "            if i==category and j==category:\n",
    "                TP += cf[i][j]\n",
    "            elif i==category and j!=category:\n",
    "                FN += cf[i][j]\n",
    "            elif i!=category and j==category:\n",
    "                FP += cf[i][j]\n",
    "            else:\n",
    "                TN += cf[i][j]\n",
    "    print classes.get(category)\n",
    "    print TP, FN, FP, TN\n",
    "    print \"Precision: \" , TP/(TP+FP)\n",
    "    print \"Recall: \" , TP/(TP+FN)\n",
    "    print \" \"\n",
    "    TrueP.append(TP)\n",
    "    FalseN.append(FN)\n",
    "    FalseP.append(FP)\n",
    "    TrueN.append(TN)\n",
    "    \n",
    "# Average confusion matrix for all classes\n",
    "TP = np.sum(TrueP)\n",
    "FN = np.sum(FalseN)\n",
    "FP = np.sum(FalseP)\n",
    "TN = np.sum(TrueN)  \n",
    "\n",
    "print  \"hey \",  TP, FN, FP, TN\n",
    "\n",
    "# PPV = TP / (TP + FP) \n",
    "# TPR = TP / (TP + FN)\n",
    "# Fscore = 2 * ((PPV * TPR)/(PPV + TPR))\n",
    "\n",
    "# print \" \"\n",
    "# print \"Precision: \" , PPV\n",
    "# print \"Recall: \" , TPR\n",
    "# print \"F-score: \" , Fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92913386,  0.93333333,  0.99310345,  0.83146067,  0.90909091,\n",
       "        0.85333333,  0.99212598,  0.78787879])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate f-score for each category\n",
    "f1_score(y_testArray,pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score\n",
      "-----\n",
      "Weighted:  0.919964940347\n",
      "Micro:  0.92\n",
      "Macro:  0.903682541074\n"
     ]
    }
   ],
   "source": [
    "# calculate f-score for all \n",
    "print \"F-score\\n-----\"\n",
    "print \"Weighted: \", f1_score(y_testArray,pred, average='weighted')\n",
    "print \"Micro: \", f1_score(y_testArray,pred, average='micro')\n",
    "print \"Macro: \", f1_score(y_testArray,pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save to pickle\n",
    "import pickle\n",
    "\n",
    "with open('categorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "    \n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REALLY NEW DATA OMGGGGG!!\n",
    "#UAAP: Ateneo pilay kontra FEU By Elech Dawa March 9 na news ni siya\n",
    "arr = \"target ateneo first round sweep harap far eastern university ngayon araw uaap season mens football tournament moro lorenzo field sikap blue eag­les  dagit sweep wala league-leading goalscorer jarvey gayoso nabigyan si sopho­more striker gayoso five goals season dalawa yellow cards suspendido laro kontra tamaraws kaldag una laro ust nu salo fourth place points kritikal laro dalawa habol sa final four bayani gayoso rookies sam lim enzo ceniza may maximum points ateneo lima puntos una segundong up feu tigatlong goals isasalpak ngayong season lim at ceniza nais tamaraws balik tikas depensa laban blue eagles\"\n",
    "testing = vectorizer.transform([arr])\n",
    "clf.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = raw_input(\"Enter:\")\n",
    "a = remove_punct_num.removePunctuationAndNumbers(a)\n",
    "a = remove_stopwords.remove_stopwords(a)\n",
    "a = stemmer2.stem(a)\n",
    "testing = vectorizer.transform([a])\n",
    "clf.predict(testing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
